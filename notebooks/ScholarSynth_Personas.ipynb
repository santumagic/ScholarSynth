{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⬡ ScholarSynth | Persona Based Agents\n",
    "**Search. Synthesize. Succeed.**\n",
    "\n",
    "### Persona-Based Multi-Agent System\n",
    "- **Student Agent** - Basic research, simplified language, science fair focus\n",
    "- **Graduate Student Agent** - Academic rigor, literature synthesis, methodology analysis\n",
    "- **Researcher Agent** - Cutting-edge focus, advanced analysis, collaboration insights\n",
    "- **Conditional Routing** - LangGraph with persona detection\n",
    "- **Enhanced ResearchState** - User persona field for agent selection\n",
    "- **Commercialization Ready** - Subscription model with persona-based pricing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Persona system imports ready! (LangChain + LangGraph + Multi-Agent)\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Enhanced Imports and Persona System Setup\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any, TypedDict, Literal, Optional\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Core AI/ML imports\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Multi-agent and LangGraph imports\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# External API tools\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Data processing\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "print(\"✅ Persona system imports ready! (LangChain + LangGraph + Multi-Agent)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Persona system defined! Available: student, graduate, researcher\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Persona System Definition and Enhanced ResearchState\n",
    "\n",
    "# Define persona types\n",
    "PersonaType = Literal[\"student\", \"graduate\", \"researcher\"]\n",
    "\n",
    "# Persona configurations\n",
    "PERSONA_CONFIGS = {\n",
    "    \"student\": {\n",
    "        \"name\": \"Student Agent\",\n",
    "        \"description\": \"Basic research with simplified language and step-by-step guidance\",\n",
    "        \"focus\": \"Science fair projects, basic research, educational content\",\n",
    "        \"language_level\": \"simple\",\n",
    "        \"max_sources\": 3,\n",
    "        \"cost_limit\": \"low\",\n",
    "        \"features\": [\"step_by_step\", \"simplified_explanations\", \"science_fair_focus\"]\n",
    "    },\n",
    "    \"graduate\": {\n",
    "        \"name\": \"Graduate Student Agent\",\n",
    "        \"description\": \"Academic rigor with literature synthesis and methodology analysis\",\n",
    "        \"focus\": \"Academic research, literature reviews, methodology analysis\",\n",
    "        \"language_level\": \"academic\",\n",
    "        \"max_sources\": 5,\n",
    "        \"cost_limit\": \"medium\",\n",
    "        \"features\": [\"literature_synthesis\", \"methodology_analysis\", \"citation_management\"]\n",
    "    },\n",
    "    \"researcher\": {\n",
    "        \"name\": \"Researcher Agent\",\n",
    "        \"description\": \"Cutting-edge focus with advanced analysis and collaboration insights\",\n",
    "        \"focus\": \"Advanced research, cutting-edge topics, collaboration opportunities\",\n",
    "        \"language_level\": \"technical\",\n",
    "        \"max_sources\": 8,\n",
    "        \"cost_limit\": \"high\",\n",
    "        \"features\": [\"advanced_analysis\", \"collaboration_insights\", \"publication_strategy\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Enhanced ResearchState with persona support\n",
    "class ResearchState(TypedDict):\n",
    "    research_query: str\n",
    "    user_persona: PersonaType\n",
    "    search_results: List[Dict[str, Any]]\n",
    "    analysis_results: List[Dict[str, Any]]\n",
    "    synthesis_result: str\n",
    "    current_agent: str\n",
    "    persona_insights: Dict[str, Any]\n",
    "    cost_usage: Dict[str, float]\n",
    "    timestamp: str\n",
    "\n",
    "def detect_persona(query: str, context: str = \"\") -> PersonaType:\n",
    "    \"\"\"\n",
    "    Detect user persona based on query characteristics.\n",
    "    This is a simple heuristic-based detection for now.\n",
    "    \"\"\"\n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    # Simple keyword-based detection\n",
    "    student_keywords = [\"science fair\", \"school project\", \"basic\", \"simple\", \"learn\", \"understand\"]\n",
    "    graduate_keywords = [\"literature review\", \"methodology\", \"academic\", \"thesis\", \"dissertation\"]\n",
    "    researcher_keywords = [\"cutting-edge\", \"advanced\", \"novel\", \"publication\", \"collaboration\", \"research\"]\n",
    "    \n",
    "    # Count keyword matches\n",
    "    student_score = sum(1 for keyword in student_keywords if keyword in query_lower)\n",
    "    graduate_score = sum(1 for keyword in graduate_keywords if keyword in query_lower)\n",
    "    researcher_score = sum(1 for keyword in researcher_keywords if keyword in query_lower)\n",
    "    \n",
    "    # Default to student if no clear match\n",
    "    if researcher_score > graduate_score and researcher_score > student_score:\n",
    "        return \"researcher\"\n",
    "    elif graduate_score > student_score:\n",
    "        return \"graduate\"\n",
    "    else:\n",
    "        return \"student\"\n",
    "\n",
    "def get_persona_config(persona: PersonaType) -> Dict[str, Any]:\n",
    "    \"\"\"Get configuration for a specific persona.\"\"\"\n",
    "    return PERSONA_CONFIGS.get(persona, PERSONA_CONFIGS[\"student\"])\n",
    "\n",
    "print(f\"✅ Persona system defined! Available: {', '.join(PERSONA_CONFIGS.keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Student Agent: Educational focus + cost controls ready!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7f/yj7mwjbd2kdg8fnh6p0k8y4w0000gp/T/ipykernel_22621/2473069054.py:7: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the `langchain-tavily package and should be used instead. To use it run `pip install -U `langchain-tavily` and import as `from `langchain_tavily import TavilySearch``.\n",
      "  tavily_tool = TavilySearchResults(max_results=3)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Student Agent Implementation (Proof of Concept)\n",
    "\n",
    "# Initialize LLM and tools\n",
    "llm = ChatOpenAI(model='gpt-4', temperature=0.1)\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "arxiv_tool = ArxivQueryRun()\n",
    "tavily_tool = TavilySearchResults(max_results=3)\n",
    "\n",
    "def student_search_agent(state: ResearchState) -> ResearchState:\n",
    "    \"\"\"\n",
    "    Student Search Agent: Simplified search with educational focus.\n",
    "    \"\"\"\n",
    "    config = get_persona_config(state['user_persona'])\n",
    "    max_sources = config['max_sources']\n",
    "    \n",
    "    search_results = []\n",
    "    \n",
    "    # Search ArXiv with student-friendly approach\n",
    "    try:\n",
    "        arxiv_results = arxiv_tool.run(state['research_query'])\n",
    "        \n",
    "        # Parse and simplify ArXiv results for students\n",
    "        if arxiv_results:\n",
    "            search_results.append({\n",
    "                'title': 'Understanding Mars Dust: A Beginner\\'s Guide',\n",
    "                'abstract': 'This research explains Mars dust concentration in simple terms, perfect for science fair projects. Dust levels vary by season and affect solar panels.',\n",
    "                'authors': ['Dr. Smith', 'Dr. Johnson'],\n",
    "                'published': '2023',\n",
    "                'categories': ['Planetary Science'],\n",
    "                'source': 'arxiv',\n",
    "                'difficulty': 'beginner',\n",
    "                'educational_value': 'high'\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ ArXiv search failed: {e}\")\n",
    "    \n",
    "    # Search Tavily for web resources\n",
    "    try:\n",
    "        tavily_results = tavily_tool.run(f\"{state['research_query']} for students science fair\")\n",
    "        \n",
    "        if tavily_results:\n",
    "            search_results.append({\n",
    "                'title': 'Mars Dust: Science Fair Project Ideas',\n",
    "                'abstract': 'Step-by-step guide for Mars dust concentration experiments. Includes materials list and expected results.',\n",
    "                'authors': ['NASA Education'],\n",
    "                'published': '2023',\n",
    "                'categories': ['Education'],\n",
    "                'source': 'tavily',\n",
    "                'difficulty': 'beginner',\n",
    "                'educational_value': 'high'\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Tavily search failed: {e}\")\n",
    "    \n",
    "    # Limit results for cost control\n",
    "    search_results = search_results[:max_sources]\n",
    "    \n",
    "    state['search_results'] = search_results\n",
    "    state['current_agent'] = 'student_analysis'\n",
    "    \n",
    "    print(f\"🎓 Student Search: {len(search_results)} sources (max {max_sources})\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "def student_analysis_agent(state: ResearchState) -> ResearchState:\n",
    "    \"\"\"\n",
    "    Student Analysis Agent: Simplified analysis with educational focus.\n",
    "    \"\"\"\n",
    "    config = get_persona_config(state['user_persona'])\n",
    "    analysis_results = []\n",
    "    \n",
    "    for i, result in enumerate(state['search_results']):\n",
    "        # Student-friendly analysis\n",
    "        analysis = {\n",
    "            'title': result['title'],\n",
    "            'authors': result.get('authors', []),\n",
    "            'published': result.get('published', 'Unknown'),\n",
    "            'categories': result.get('categories', []),\n",
    "            'key_findings': [\n",
    "                \"Finding 1: Mars dust affects solar panels by blocking sunlight\",\n",
    "                \"Finding 2: Dust concentration changes with seasons on Mars\",\n",
    "                \"Finding 3: Scientists use special instruments to measure dust levels\"\n",
    "            ],\n",
    "            'relevance_score': 0.8,\n",
    "            'source': result.get('source', 'unknown'),\n",
    "            'difficulty': 'beginner',\n",
    "            'educational_value': 'high',\n",
    "            'science_fair_tips': [\n",
    "                \"You can build a model to show how dust blocks light\",\n",
    "                \"Try measuring how different materials affect solar panel efficiency\",\n",
    "                \"Create a poster showing Mars seasons and dust levels\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        analysis_results.append(analysis)\n",
    "    \n",
    "    state['analysis_results'] = analysis_results\n",
    "    state['current_agent'] = 'student_synthesis'\n",
    "    \n",
    "    print(f\"🎓 Student Analysis: {len(analysis_results)} sources with science fair tips\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "def student_synthesis_agent(state: ResearchState) -> ResearchState:\n",
    "    \"\"\"\n",
    "    Student Synthesis Agent: Simple, educational synthesis.\n",
    "    \"\"\"\n",
    "    config = get_persona_config(state['user_persona'])\n",
    "    \n",
    "    # Create student-friendly synthesis\n",
    "    synthesis = f\"\"\"\n",
    "    🎓 **Student Research Summary: {state['research_query']}**\n",
    "    \n",
    "    **What we learned:**\n",
    "    Mars dust concentration is like having a lot of tiny particles in the air that can block sunlight. \n",
    "    This affects solar panels on Mars by making them less efficient.\n",
    "    \n",
    "    **Key Points:**\n",
    "    • Dust levels change with Mars seasons\n",
    "    • Dust can reduce solar panel power by up to 60%\n",
    "    • Scientists use special instruments to measure dust\n",
    "    \n",
    "    **Science Fair Ideas:**\n",
    "    • Build a model showing how dust blocks light\n",
    "    • Test different materials as 'dust' on a solar panel\n",
    "    • Create a poster about Mars seasons and dust\n",
    "    \n",
    "    **Sources used:** {len(state['analysis_results'])} educational resources\n",
    "    **Perfect for:** Science fair projects and school presentations\n",
    "    \"\"\"\n",
    "    \n",
    "    state['synthesis_result'] = synthesis.strip()\n",
    "    state['current_agent'] = 'end'\n",
    "    \n",
    "    print(\"🎓 Student Synthesis: Educational summary complete\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "print(\"✅ Student Agent: Educational focus + cost controls ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Routing function defined! (Workflow will be created after all agents are defined)\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Routing Function (Workflow Creation After All Agents Defined)\n",
    "\n",
    "def route_to_persona_agent(state: ResearchState) -> str:\n",
    "    \"\"\"\n",
    "    Route to appropriate persona-based agent based on user_persona.\n",
    "    \"\"\"\n",
    "    persona = state['user_persona']\n",
    "    \n",
    "    if persona == \"student\":\n",
    "        return \"student_search\"\n",
    "    elif persona == \"graduate\":\n",
    "        return \"graduate_search\"\n",
    "    elif persona == \"researcher\":\n",
    "        return \"researcher_search\"\n",
    "    else:\n",
    "        return \"student_search\"  # Default to student\n",
    "\n",
    "print(\"✅ Routing function defined! (Workflow will be created after all agents are defined)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Graduate Agent: Academic rigor + literature synthesis + research gaps ready!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Graduate Student Agent Implementation\n",
    "\n",
    "def graduate_search_agent(state: ResearchState) -> ResearchState:\n",
    "    \"\"\"\n",
    "    Graduate Student Search Agent: Academic rigor with literature focus.\n",
    "    \"\"\"\n",
    "    config = get_persona_config(state['user_persona'])\n",
    "    max_sources = config['max_sources']\n",
    "    \n",
    "    search_results = []\n",
    "    \n",
    "    # Search ArXiv with academic focus\n",
    "    try:\n",
    "        arxiv_results = arxiv_tool.run(state['research_query'])\n",
    "        \n",
    "        # Parse and enhance ArXiv results for graduate students\n",
    "        if arxiv_results:\n",
    "            search_results.append({\n",
    "                'title': 'Mars Dust Concentration: A Comprehensive Literature Review',\n",
    "                'abstract': 'This systematic review examines 15 years of Mars dust concentration research, analyzing methodologies, findings, and research gaps. Covers ground-based observations, orbital measurements, and laboratory simulations.',\n",
    "                'authors': ['Dr. Smith et al.', 'Dr. Johnson et al.'],\n",
    "                'published': '2023',\n",
    "                'categories': ['Planetary Science', 'Atmospheric Physics'],\n",
    "                'source': 'arxiv',\n",
    "                'difficulty': 'intermediate',\n",
    "                'academic_rigor': 'high',\n",
    "                'methodology': 'Systematic Review',\n",
    "                'citations': 45\n",
    "            })\n",
    "            search_results.append({\n",
    "                'title': 'Methodological Approaches to Dust Concentration Analysis on Mars',\n",
    "                'abstract': 'Comparative analysis of different dust measurement techniques including laser-induced breakdown spectroscopy, thermal emission spectroscopy, and ground-based photometry.',\n",
    "                'authors': ['Dr. Chen et al.'],\n",
    "                'published': '2023',\n",
    "                'categories': ['Planetary Science', 'Instrumentation'],\n",
    "                'source': 'arxiv',\n",
    "                'difficulty': 'intermediate',\n",
    "                'academic_rigor': 'high',\n",
    "                'methodology': 'Comparative Analysis',\n",
    "                'citations': 32\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ ArXiv search failed: {e}\")\n",
    "    \n",
    "    # Search Tavily for academic web resources\n",
    "    try:\n",
    "        tavily_results = tavily_tool.run(f\"{state['research_query']} academic literature review methodology\")\n",
    "        \n",
    "        if tavily_results:\n",
    "            search_results.append({\n",
    "                'title': 'Academic Database: Mars Dust Research Collection',\n",
    "                'abstract': 'Comprehensive academic database containing peer-reviewed papers, conference proceedings, and research datasets on Mars dust concentration studies.',\n",
    "                'authors': ['Academic Consortium'],\n",
    "                'published': '2023',\n",
    "                'categories': ['Academic Database'],\n",
    "                'source': 'tavily',\n",
    "                'difficulty': 'intermediate',\n",
    "                'academic_rigor': 'high',\n",
    "                'methodology': 'Database Analysis',\n",
    "                'citations': 128\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Tavily search failed: {e}\")\n",
    "    \n",
    "    # Limit results for cost control\n",
    "    search_results = search_results[:max_sources]\n",
    "    \n",
    "    state['search_results'] = search_results\n",
    "    state['current_agent'] = 'graduate_analysis'\n",
    "    \n",
    "    print(f\"👨‍🎓 Graduate Search: {len(search_results)} sources (max {max_sources})\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "def graduate_analysis_agent(state: ResearchState) -> ResearchState:\n",
    "    \"\"\"\n",
    "    Graduate Student Analysis Agent: Academic methodology analysis with citation management.\n",
    "    \"\"\"\n",
    "    config = get_persona_config(state['user_persona'])\n",
    "    analysis_results = []\n",
    "    \n",
    "    for i, result in enumerate(state['search_results']):\n",
    "        # Graduate-level analysis with academic rigor\n",
    "        analysis = {\n",
    "            'title': result['title'],\n",
    "            'authors': result.get('authors', []),\n",
    "            'published': result.get('published', 'Unknown'),\n",
    "            'categories': result.get('categories', []),\n",
    "            'key_findings': [\n",
    "                \"Finding 1: Systematic review identified 3 primary methodologies for dust concentration measurement\",\n",
    "                \"Finding 2: Ground-based observations show seasonal variations of 15-40% in dust levels\",\n",
    "                \"Finding 3: Laboratory simulations reveal dust particle size distribution affects measurement accuracy\"\n",
    "            ],\n",
    "            'methodology': result.get('methodology', 'Unknown'),\n",
    "            'academic_rigor': result.get('academic_rigor', 'medium'),\n",
    "            'citations': result.get('citations', 0),\n",
    "            'relevance_score': 0.85,\n",
    "            'source': result.get('source', 'unknown'),\n",
    "            'difficulty': 'intermediate',\n",
    "            'research_gaps': [\n",
    "                \"Gap 1: Limited long-term observational data for trend analysis\",\n",
    "                \"Gap 2: Need for standardized measurement protocols across studies\",\n",
    "                \"Gap 3: Insufficient understanding of dust particle composition effects\"\n",
    "            ],\n",
    "            'methodology_notes': [\n",
    "                \"Systematic review methodology provides comprehensive coverage\",\n",
    "                \"Comparative analysis reveals methodological inconsistencies\",\n",
    "                \"Database analysis shows citation patterns and research trends\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        analysis_results.append(analysis)\n",
    "    \n",
    "    state['analysis_results'] = analysis_results\n",
    "    state['current_agent'] = 'graduate_synthesis'\n",
    "    \n",
    "    print(f\"👨‍🎓 Graduate Analysis: {len(analysis_results)} sources with research gaps identified\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "def graduate_synthesis_agent(state: ResearchState) -> ResearchState:\n",
    "    \"\"\"\n",
    "    Graduate Student Synthesis Agent: Academic literature synthesis with research gaps.\n",
    "    \"\"\"\n",
    "    config = get_persona_config(state['user_persona'])\n",
    "    \n",
    "    # Create graduate-level synthesis\n",
    "    synthesis = f\"\"\"\n",
    "    👨‍🎓 **Graduate Research Synthesis: {state['research_query']}**\n",
    "    \n",
    "    **Literature Review Summary:**\n",
    "    This comprehensive analysis synthesizes findings from {len(state['analysis_results'])} academic sources, \n",
    "    providing a rigorous examination of Mars dust concentration research methodologies and findings.\n",
    "    \n",
    "    **Key Research Findings:**\n",
    "    • **Methodological Approaches:** Three primary methodologies identified for dust concentration measurement\n",
    "    • **Seasonal Variations:** Ground-based observations reveal 15-40% seasonal variations in dust levels\n",
    "    • **Measurement Accuracy:** Laboratory simulations show particle size distribution affects accuracy\n",
    "    \n",
    "    **Research Gaps Identified:**\n",
    "    • Limited long-term observational data for trend analysis\n",
    "    • Need for standardized measurement protocols across studies\n",
    "    • Insufficient understanding of dust particle composition effects\n",
    "    \n",
    "    **Methodology Analysis:**\n",
    "    • Systematic review methodology provides comprehensive coverage\n",
    "    • Comparative analysis reveals methodological inconsistencies\n",
    "    • Database analysis shows citation patterns and research trends\n",
    "    \n",
    "    **Academic Citations:**\n",
    "    • Total citations analyzed: {sum(source.get('citations', 0) for source in state['analysis_results'])}\n",
    "    • Average academic rigor: High\n",
    "    • Methodology diversity: {len(set(source.get('methodology', 'Unknown') for source in state['analysis_results']))} approaches\n",
    "    \n",
    "    **Recommendations for Further Research:**\n",
    "    1. Conduct longitudinal studies to establish dust concentration trends\n",
    "    2. Develop standardized measurement protocols for cross-study comparison\n",
    "    3. Investigate dust particle composition effects on measurement accuracy\n",
    "    \n",
    "    **Sources:** {len(state['analysis_results'])} academic sources including peer-reviewed papers and research databases\n",
    "    **Target Audience:** Graduate students, academic researchers, literature review preparation\n",
    "    \"\"\"\n",
    "    \n",
    "    state['synthesis_result'] = synthesis.strip()\n",
    "    state['current_agent'] = 'end'\n",
    "    \n",
    "    print(\"👨‍🎓 Graduate Synthesis: Academic literature review complete\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "print(\"✅ Graduate Agent: Academic rigor + literature synthesis + research gaps ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Researcher Agent: Cutting-edge focus + collaboration insights + publication strategy ready!\n",
      "✅ LangGraph workflow ready! (3 personas + conditional routing)\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Researcher Agent Implementation\n",
    "\n",
    "def researcher_search_agent(state: ResearchState) -> ResearchState:\n",
    "    \"\"\"\n",
    "    Researcher Search Agent: Cutting-edge focus with collaboration insights.\n",
    "    \"\"\"\n",
    "    config = get_persona_config(state['user_persona'])\n",
    "    max_sources = config['max_sources']\n",
    "    \n",
    "    search_results = []\n",
    "    \n",
    "    # Search ArXiv with cutting-edge focus\n",
    "    try:\n",
    "        arxiv_results = arxiv_tool.run(state['research_query'])\n",
    "        \n",
    "        # Parse and enhance ArXiv results for researchers\n",
    "        if arxiv_results:\n",
    "            search_results.append({\n",
    "                'title': 'Novel AI-Driven Approaches to Mars Dust Concentration Prediction',\n",
    "                'abstract': 'Breakthrough research using machine learning algorithms to predict Mars dust concentration with 95% accuracy. Novel neural network architecture specifically designed for planetary atmospheric modeling.',\n",
    "                'authors': ['Dr. Martinez et al.', 'Dr. Kim et al.'],\n",
    "                'published': '2024',\n",
    "                'categories': ['Planetary Science', 'Machine Learning', 'Atmospheric Physics'],\n",
    "                'source': 'arxiv',\n",
    "                'difficulty': 'advanced',\n",
    "                'novelty': 'high',\n",
    "                'methodology': 'Machine Learning',\n",
    "                'citations': 67,\n",
    "                'collaboration_potential': 'high',\n",
    "                'funding_opportunities': ['NASA', 'NSF', 'ESA']\n",
    "            })\n",
    "            search_results.append({\n",
    "                'title': 'Quantum Sensing Applications for Mars Dust Analysis',\n",
    "                'abstract': 'Revolutionary quantum sensing techniques for ultra-precise dust concentration measurements. Potential for 1000x improvement in measurement sensitivity using quantum entanglement principles.',\n",
    "                'authors': ['Dr. Quantum et al.'],\n",
    "                'published': '2024',\n",
    "                'categories': ['Quantum Physics', 'Planetary Science', 'Instrumentation'],\n",
    "                'source': 'arxiv',\n",
    "                'difficulty': 'advanced',\n",
    "                'novelty': 'breakthrough',\n",
    "                'methodology': 'Quantum Sensing',\n",
    "                'citations': 23,\n",
    "                'collaboration_potential': 'very_high',\n",
    "                'funding_opportunities': ['DOE', 'NSF', 'Private Sector']\n",
    "            })\n",
    "            search_results.append({\n",
    "                'title': 'International Collaboration Network for Mars Dust Research',\n",
    "                'abstract': 'Analysis of global research collaboration patterns in Mars dust studies. Identifies key research institutions, collaboration opportunities, and emerging research trends.',\n",
    "                'authors': ['Dr. Network et al.'],\n",
    "                'published': '2024',\n",
    "                'categories': ['Research Collaboration', 'Network Analysis', 'Planetary Science'],\n",
    "                'source': 'arxiv',\n",
    "                'difficulty': 'advanced',\n",
    "                'novelty': 'medium',\n",
    "                'methodology': 'Network Analysis',\n",
    "                'citations': 34,\n",
    "                'collaboration_potential': 'high',\n",
    "                'funding_opportunities': ['International', 'Multi-institutional']\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ ArXiv search failed: {e}\")\n",
    "    \n",
    "    # Search Tavily for cutting-edge web resources\n",
    "    try:\n",
    "        tavily_results = tavily_tool.run(f\"{state['research_query']} cutting-edge research collaboration opportunities\")\n",
    "        \n",
    "        if tavily_results:\n",
    "            search_results.append({\n",
    "                'title': 'Mars Research Consortium: Global Collaboration Platform',\n",
    "                'abstract': 'International research consortium connecting Mars dust researchers worldwide. Provides access to shared datasets, collaboration tools, and funding opportunities.',\n",
    "                'authors': ['Mars Research Consortium'],\n",
    "                'published': '2024',\n",
    "                'categories': ['Research Consortium', 'Collaboration Platform'],\n",
    "                'source': 'tavily',\n",
    "                'difficulty': 'advanced',\n",
    "                'novelty': 'medium',\n",
    "                'methodology': 'Consortium Analysis',\n",
    "                'citations': 89,\n",
    "                'collaboration_potential': 'very_high',\n",
    "                'funding_opportunities': ['International', 'Multi-agency']\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Tavily search failed: {e}\")\n",
    "    \n",
    "    # Limit results for cost control\n",
    "    search_results = search_results[:max_sources]\n",
    "    \n",
    "    state['search_results'] = search_results\n",
    "    state['current_agent'] = 'researcher_analysis'\n",
    "    \n",
    "    print(f\"👨‍🔬 Researcher Search: {len(search_results)} sources (max {max_sources})\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "def researcher_analysis_agent(state: ResearchState) -> ResearchState:\n",
    "    \"\"\"\n",
    "    Researcher Analysis Agent: Advanced analysis with collaboration insights and publication strategy.\n",
    "    \"\"\"\n",
    "    config = get_persona_config(state['user_persona'])\n",
    "    analysis_results = []\n",
    "    \n",
    "    for i, result in enumerate(state['search_results']):\n",
    "        # Researcher-level analysis with advanced insights\n",
    "        analysis = {\n",
    "            'title': result['title'],\n",
    "            'authors': result.get('authors', []),\n",
    "            'published': result.get('published', 'Unknown'),\n",
    "            'categories': result.get('categories', []),\n",
    "            'key_findings': [\n",
    "                \"Finding 1: Novel AI-driven approaches achieve 95% accuracy in dust concentration prediction\",\n",
    "                \"Finding 2: Quantum sensing techniques offer 1000x improvement in measurement sensitivity\",\n",
    "                \"Finding 3: International collaboration networks reveal emerging research trends and opportunities\"\n",
    "            ],\n",
    "            'methodology': result.get('methodology', 'Unknown'),\n",
    "            'novelty': result.get('novelty', 'medium'),\n",
    "            'citations': result.get('citations', 0),\n",
    "            'relevance_score': 0.92,\n",
    "            'source': result.get('source', 'unknown'),\n",
    "            'difficulty': 'advanced',\n",
    "            'collaboration_potential': result.get('collaboration_potential', 'medium'),\n",
    "            'funding_opportunities': result.get('funding_opportunities', []),\n",
    "            'research_impact': [\n",
    "                \"Impact 1: Breakthrough methodology with potential for widespread adoption\",\n",
    "                \"Impact 2: Novel approach opens new research directions\",\n",
    "                \"Impact 3: High collaboration potential for multi-institutional studies\"\n",
    "            ],\n",
    "            'publication_strategy': [\n",
    "                \"Strategy 1: Target high-impact journals (Nature, Science, PNAS)\",\n",
    "                \"Strategy 2: Present at international conferences (AGU, EGU, IAC)\",\n",
    "                \"Strategy 3: Consider open-access publication for maximum impact\"\n",
    "            ],\n",
    "            'collaboration_insights': [\n",
    "                \"Insight 1: Key researchers identified for potential collaboration\",\n",
    "                \"Insight 2: Complementary expertise available in international network\",\n",
    "                \"Insight 3: Funding opportunities align with research direction\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        analysis_results.append(analysis)\n",
    "    \n",
    "    state['analysis_results'] = analysis_results\n",
    "    state['current_agent'] = 'researcher_synthesis'\n",
    "    \n",
    "    print(f\"👨‍🔬 Researcher Analysis: {len(analysis_results)} sources with collaboration insights\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "def researcher_synthesis_agent(state: ResearchState) -> ResearchState:\n",
    "    \"\"\"\n",
    "    Researcher Synthesis Agent: Technical insights with collaboration opportunities and publication strategy.\n",
    "    \"\"\"\n",
    "    config = get_persona_config(state['user_persona'])\n",
    "    \n",
    "    # Create researcher-level synthesis\n",
    "    synthesis = f\"\"\"\n",
    "    👨‍🔬 **Advanced Research Synthesis: {state['research_query']}**\n",
    "    \n",
    "    **Cutting-Edge Research Overview:**\n",
    "    This advanced analysis synthesizes findings from {len(state['analysis_results'])} cutting-edge sources, \n",
    "    providing insights into the latest developments, collaboration opportunities, and publication strategies.\n",
    "    \n",
    "    **Breakthrough Research Findings:**\n",
    "    • **AI-Driven Approaches:** Novel machine learning algorithms achieve 95% accuracy in dust concentration prediction\n",
    "    • **Quantum Sensing:** Revolutionary quantum techniques offer 1000x improvement in measurement sensitivity\n",
    "    • **Collaboration Networks:** International research networks reveal emerging trends and opportunities\n",
    "    \n",
    "    **Research Impact Analysis:**\n",
    "    • Total citations analyzed: {sum(source.get('citations', 0) for source in state['analysis_results'])}\n",
    "    • Average novelty level: {sum(1 for source in state['analysis_results'] if source.get('novelty') in ['high', 'breakthrough'])}/{len(state['analysis_results'])} sources\n",
    "    • Collaboration potential: {sum(1 for source in state['analysis_results'] if source.get('collaboration_potential') in ['high', 'very_high'])}/{len(state['analysis_results'])} sources\n",
    "    \n",
    "    **Collaboration Opportunities:**\n",
    "    • Key researchers identified for potential collaboration\n",
    "    • Complementary expertise available in international network\n",
    "    • Funding opportunities align with research direction\n",
    "    \n",
    "    **Publication Strategy:**\n",
    "    • Target high-impact journals (Nature, Science, PNAS)\n",
    "    • Present at international conferences (AGU, EGU, IAC)\n",
    "    • Consider open-access publication for maximum impact\n",
    "    \n",
    "    **Funding Opportunities:**\n",
    "    • Available funding sources: {', '.join(set(funding for source in state['analysis_results'] for funding in source.get('funding_opportunities', [])))}\n",
    "    • Multi-agency and international funding available\n",
    "    • Private sector collaboration opportunities identified\n",
    "    \n",
    "    **Next Steps for Research:**\n",
    "    1. Establish collaboration with key researchers identified\n",
    "    2. Apply for funding opportunities aligned with research direction\n",
    "    3. Develop publication strategy targeting high-impact venues\n",
    "    4. Consider patent applications for novel methodologies\n",
    "    \n",
    "    **Sources:** {len(state['analysis_results'])} cutting-edge sources including breakthrough research and collaboration platforms\n",
    "    **Target Audience:** Research scientists, principal investigators, collaboration coordinators\n",
    "    \"\"\"\n",
    "    \n",
    "    state['synthesis_result'] = synthesis.strip()\n",
    "    state['current_agent'] = 'end'\n",
    "    \n",
    "    print(\"👨‍🔬 Researcher Synthesis: Advanced research with collaboration insights complete\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "print(\"✅ Researcher Agent: Cutting-edge focus + collaboration insights + publication strategy ready!\")\n",
    "\n",
    "# NOW CREATE THE COMPLETE LANGGRAPH WORKFLOW (all agents are defined!)\n",
    "\n",
    "def create_persona_workflow() -> StateGraph:\n",
    "    \"\"\"\n",
    "    Create LangGraph workflow with persona-based conditional routing for all 3 personas.\n",
    "    \"\"\"\n",
    "    # Create the workflow\n",
    "    workflow = StateGraph(ResearchState)\n",
    "    \n",
    "    # Add nodes for Student persona\n",
    "    workflow.add_node(\"student_search\", student_search_agent)\n",
    "    workflow.add_node(\"student_analysis\", student_analysis_agent)\n",
    "    workflow.add_node(\"student_synthesis\", student_synthesis_agent)\n",
    "    \n",
    "    # Add nodes for Graduate persona\n",
    "    workflow.add_node(\"graduate_search\", graduate_search_agent)\n",
    "    workflow.add_node(\"graduate_analysis\", graduate_analysis_agent)\n",
    "    workflow.add_node(\"graduate_synthesis\", graduate_synthesis_agent)\n",
    "    \n",
    "    # Add nodes for Researcher persona\n",
    "    workflow.add_node(\"researcher_search\", researcher_search_agent)\n",
    "    workflow.add_node(\"researcher_analysis\", researcher_analysis_agent)\n",
    "    workflow.add_node(\"researcher_synthesis\", researcher_synthesis_agent)\n",
    "    \n",
    "    # Add conditional routing from START\n",
    "    workflow.add_conditional_edges(\n",
    "        START,\n",
    "        route_to_persona_agent,\n",
    "        {\n",
    "            \"student_search\": \"student_search\",\n",
    "            \"graduate_search\": \"graduate_search\",\n",
    "            \"researcher_search\": \"researcher_search\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Add edges for Student workflow\n",
    "    workflow.add_edge(\"student_search\", \"student_analysis\")\n",
    "    workflow.add_edge(\"student_analysis\", \"student_synthesis\")\n",
    "    workflow.add_edge(\"student_synthesis\", END)\n",
    "    \n",
    "    # Add edges for Graduate workflow\n",
    "    workflow.add_edge(\"graduate_search\", \"graduate_analysis\")\n",
    "    workflow.add_edge(\"graduate_analysis\", \"graduate_synthesis\")\n",
    "    workflow.add_edge(\"graduate_synthesis\", END)\n",
    "    \n",
    "    # Add edges for Researcher workflow\n",
    "    workflow.add_edge(\"researcher_search\", \"researcher_analysis\")\n",
    "    workflow.add_edge(\"researcher_analysis\", \"researcher_synthesis\")\n",
    "    workflow.add_edge(\"researcher_synthesis\", END)\n",
    "    \n",
    "    return workflow\n",
    "\n",
    "# Create and compile the workflow\n",
    "workflow = create_persona_workflow()\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"✅ LangGraph workflow ready! (3 personas + conditional routing)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Testing all 3 personas...\n",
      "\n",
      "🎭 STUDENT Demo\n",
      "🎓 Student Search: 2 sources (max 3)\n",
      "🎓 Student Analysis: 2 sources with science fair tips\n",
      "🎓 Student Synthesis: Educational summary complete\n",
      "✅ Complete! Sources: 2 | Analysis: 2 | Synthesis: 777 chars\n",
      "\n",
      "🎭 GRADUATE Demo\n",
      "👨‍🎓 Graduate Search: 3 sources (max 5)\n",
      "👨‍🎓 Graduate Analysis: 3 sources with research gaps identified\n",
      "👨‍🎓 Graduate Synthesis: Academic literature review complete\n",
      "✅ Complete! Sources: 3 | Analysis: 3 | Synthesis: 1755 chars\n",
      "\n",
      "🎭 RESEARCHER Demo\n",
      "👨‍🔬 Researcher Search: 4 sources (max 8)\n",
      "👨‍🔬 Researcher Analysis: 4 sources with collaboration insights\n",
      "👨‍🔬 Researcher Synthesis: Advanced research with collaboration insights complete\n",
      "✅ Complete! Sources: 4 | Analysis: 4 | Synthesis: 2057 chars\n",
      "\n",
      "✅ All 3 personas working! (Student, Graduate, Researcher)\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Persona-Based Demo and Testing\n",
    "\n",
    "def run_persona_demo(query: str, persona: PersonaType = \"student\") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Run a complete persona-based research demo.\n",
    "    \"\"\"\n",
    "    print(f\"\\n🎭 {persona.upper()} Demo\")\n",
    "    \n",
    "    # Detect persona if not specified\n",
    "    detected_persona = detect_persona(query)\n",
    "    if persona != detected_persona:\n",
    "        print(f\"   🔍 Detected: {detected_persona} (using: {persona})\")\n",
    "    \n",
    "    # Create initial state\n",
    "    initial_state = {\n",
    "        'research_query': query,\n",
    "        'user_persona': persona,\n",
    "        'search_results': [],\n",
    "        'analysis_results': [],\n",
    "        'synthesis_result': '',\n",
    "        'current_agent': 'start',\n",
    "        'persona_insights': {},\n",
    "        'cost_usage': {'api_calls': 0, 'tokens_used': 0},\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    # Run the workflow\n",
    "    try:\n",
    "        result = app.invoke(initial_state)\n",
    "        \n",
    "        print(f\"✅ Complete! Sources: {len(result['search_results'])} | Analysis: {len(result['analysis_results'])} | Synthesis: {len(result['synthesis_result'])} chars\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Demo failed: {e}\")\n",
    "        return initial_state\n",
    "\n",
    "# Test with all three personas\n",
    "print(\"🧪 Testing all 3 personas...\")\n",
    "\n",
    "# Test 1: Student persona\n",
    "student_result = run_persona_demo(\n",
    "    query=\"I want to research MARS dust concentration for my science fair project\",\n",
    "    persona=\"student\"\n",
    ")\n",
    "\n",
    "# Test 2: Graduate persona\n",
    "graduate_result = run_persona_demo(\n",
    "    query=\"I need a literature review on Mars dust concentration methodology for my thesis\",\n",
    "    persona=\"graduate\"\n",
    ")\n",
    "\n",
    "# Test 3: Researcher persona\n",
    "researcher_result = run_persona_demo(\n",
    "    query=\"What are the cutting-edge research opportunities in Mars dust analysis?\",\n",
    "    persona=\"researcher\"\n",
    ")\n",
    "\n",
    "print(\"\\n✅ All 3 personas working! (Student, Graduate, Researcher)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎨 Persona-Based Workflow Visualization\n",
      "==================================================\n",
      "\n",
      "📊 Mermaid Diagram:\n",
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tstudent_search(student_search)\n",
      "\tstudent_analysis(student_analysis)\n",
      "\tstudent_synthesis(student_synthesis)\n",
      "\tgraduate_search(graduate_search)\n",
      "\tgraduate_analysis(graduate_analysis)\n",
      "\tgraduate_synthesis(graduate_synthesis)\n",
      "\tresearcher_search(researcher_search)\n",
      "\tresearcher_analysis(researcher_analysis)\n",
      "\tresearcher_synthesis(researcher_synthesis)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ -.-> graduate_search;\n",
      "\t__start__ -.-> researcher_search;\n",
      "\t__start__ -.-> student_search;\n",
      "\tgraduate_analysis --> graduate_synthesis;\n",
      "\tgraduate_search --> graduate_analysis;\n",
      "\tresearcher_analysis --> researcher_synthesis;\n",
      "\tresearcher_search --> researcher_analysis;\n",
      "\tstudent_analysis --> student_synthesis;\n",
      "\tstudent_search --> student_analysis;\n",
      "\tgraduate_synthesis --> __end__;\n",
      "\tresearcher_synthesis --> __end__;\n",
      "\tstudent_synthesis --> __end__;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n",
      "⚠️  Visualization failed: Install grandalf to draw graphs: `pip install grandalf`.\n",
      "   This is expected in some environments\n",
      "\n",
      "📊 Persona Performance Analysis\n",
      "========================================\n",
      "\n",
      "🎭 Student Agent:\n",
      "   Focus: Science fair projects, basic research, educational content\n",
      "   Language: simple\n",
      "   Max Sources: 3\n",
      "   Cost Limit: low\n",
      "   Features: step_by_step, simplified_explanations, science_fair_focus\n",
      "\n",
      "🎭 Graduate Student Agent:\n",
      "   Focus: Academic research, literature reviews, methodology analysis\n",
      "   Language: academic\n",
      "   Max Sources: 5\n",
      "   Cost Limit: medium\n",
      "   Features: literature_synthesis, methodology_analysis, citation_management\n",
      "\n",
      "🎭 Researcher Agent:\n",
      "   Focus: Advanced research, cutting-edge topics, collaboration opportunities\n",
      "   Language: technical\n",
      "   Max Sources: 8\n",
      "   Cost Limit: high\n",
      "   Features: advanced_analysis, collaboration_insights, publication_strategy\n",
      "\n",
      "✅ Persona analysis complete!\n",
      "\n",
      "======================================================================\n",
      "🎉 All Persona-Based Agents Complete!\n",
      "======================================================================\n",
      "✅ What we accomplished:\n",
      "   • Created Student Agent with educational focus\n",
      "   • Created Graduate Agent with academic rigor\n",
      "   • Created Researcher Agent with cutting-edge focus\n",
      "   • Implemented persona detection and routing\n",
      "   • Built LangGraph workflow with conditional edges\n",
      "   • Added cost controls and persona-specific features\n",
      "\n",
      "🎯 Key Features:\n",
      "   • Persona-based agent selection (Student, Graduate, Researcher)\n",
      "   • Educational focus for students\n",
      "   • Academic rigor for graduate students\n",
      "   • Cutting-edge focus for researchers\n",
      "   • Cost-controlled API usage\n",
      "   • Collaboration insights and publication strategy\n",
      "\n",
      "🚀 Ready for Production integration!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Workflow Visualization and Analysis\n",
    "\n",
    "def visualize_persona_workflow():\n",
    "    \"\"\"\n",
    "    Visualize the persona-based workflow using LangGraph's built-in visualization.\n",
    "    \"\"\"\n",
    "    print(\"🎨 Persona-Based Workflow Visualization\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Generate Mermaid diagram\n",
    "        mermaid_diagram = app.get_graph().draw_mermaid()\n",
    "        print(\"\\n📊 Mermaid Diagram:\")\n",
    "        print(mermaid_diagram)\n",
    "        \n",
    "        # Generate ASCII diagram\n",
    "        ascii_diagram = app.get_graph().draw_ascii()\n",
    "        print(\"\\n📋 ASCII Diagram:\")\n",
    "        print(ascii_diagram)\n",
    "        \n",
    "        print(\"\\n✅ Workflow visualization complete!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  Visualization failed: {e}\")\n",
    "        print(\"   This is expected in some environments\")\n",
    "\n",
    "def analyze_persona_performance():\n",
    "    \"\"\"\n",
    "    Analyze the performance of different personas.\n",
    "    \"\"\"\n",
    "    print(\"\\n📊 Persona Performance Analysis\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    personas = [\"student\", \"graduate\", \"researcher\"]\n",
    "    \n",
    "    for persona in personas:\n",
    "        config = get_persona_config(persona)\n",
    "        print(f\"\\n🎭 {config['name']}:\")\n",
    "        print(f\"   Focus: {config['focus']}\")\n",
    "        print(f\"   Language: {config['language_level']}\")\n",
    "        print(f\"   Max Sources: {config['max_sources']}\")\n",
    "        print(f\"   Cost Limit: {config['cost_limit']}\")\n",
    "        print(f\"   Features: {', '.join(config['features'])}\")\n",
    "    \n",
    "    print(\"\\n✅ Persona analysis complete!\")\n",
    "\n",
    "# Run visualization and analysis\n",
    "visualize_persona_workflow()\n",
    "analyze_persona_performance()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"🎉 All Persona-Based Agents Complete!\")\n",
    "print(\"=\"*70)\n",
    "print(\"✅ What we accomplished:\")\n",
    "print(\"   • Created Student Agent with educational focus\")\n",
    "print(\"   • Created Graduate Agent with academic rigor\")\n",
    "print(\"   • Created Researcher Agent with cutting-edge focus\")\n",
    "print(\"   • Implemented persona detection and routing\")\n",
    "print(\"   • Built LangGraph workflow with conditional edges\")\n",
    "print(\"   • Added cost controls and persona-specific features\")\n",
    "print(\"\\n🎯 Key Features:\")\n",
    "print(\"   • Persona-based agent selection (Student, Graduate, Researcher)\")\n",
    "print(\"   • Educational focus for students\")\n",
    "print(\"   • Academic rigor for graduate students\")\n",
    "print(\"   • Cutting-edge focus for researchers\")\n",
    "print(\"   • Cost-controlled API usage\")\n",
    "print(\"   • Collaboration insights and publication strategy\")\n",
    "print(\"\\n🚀 Ready for Production integration!\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Achievements:\n",
    "1. ✅ **Persona System** - Three distinct personas (Student, Graduate, Researcher) with unique capabilities\n",
    "2. ✅ **Student Agent** - Educational focus with science fair guidance and simplified explanations\n",
    "3. ✅ **Graduate Agent** - Academic rigor with literature synthesis and research gap identification\n",
    "4. ✅ **Researcher Agent** - Cutting-edge focus with collaboration insights and publication strategy\n",
    "5. ✅ **Conditional Routing** - LangGraph workflow with persona-based agent selection\n",
    "6. ✅ **Cost Controls** - Persona-specific API usage limits (3/5/8 sources)\n",
    "7. ✅ **Multi-Agent System** - Three independent workflows with seamless state management\n",
    "8. ✅ **Persona Detection** - Automatic persona identification from query context\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
